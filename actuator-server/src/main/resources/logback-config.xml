<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- 读取服务名称 -->
    <springProperty scope="context" name="application.name" source="spring.application.name"/>
    <!-- 日志存放路径 -->
    <springProperty scope="context" name="log.path" source="log.path" defaultValue="/opt/${application.name}/logs"/>
    <!-- 日志输出格式 -->
    <springProperty scope="context" name="log.pattern" source="log.pattern"
                    defaultValue="%d{yyyy-MM-dd HH:mm:ss.SSS} [%tid] [%thread] %-5level %logger{36} -%msg%n"/>
    <springProperty scope="context" name="log.skywalking.pattern" source="log.skywalking.pattern"
                    defaultValue="%d{yyyy-MM-dd HH:mm:ss.SSS} [%X{tid}] [%thread] %-5level %logger{36} -%msg%n"/>

    <springProperty scope="context" name="APP_NAME" source="spring.application.name" defaultValue="springBoot"/>
    <!--LogStash访问host-->
    <springProperty name="LOG_STASH_HOST" scope="context" source="logstash.host" defaultValue="localhost"/>
    <!--请求模块，http设置进来-->
    <!--    <springProperty name="MODULE_TYPE" scope="context" source="logstash.host" defaultValue="1"/>-->
    <!--设备序列号，http设置进来-->
    <!--    <springProperty name="DEV_NUMBER" scope="context" source="logstash.host" defaultValue="123456"/>-->
    <!-- 单个日志文件大小 -->
    <springProperty scope="context" name="log.maxFileSize" source="log.max-file-size" defaultValue="20MB"/>
    <!-- 日志最大历史天数 -->
    <springProperty scope="context" name="log.maxHistory" source="log.max-history" defaultValue="60"/>
    <!-- 日志文件总大小 -->
    <springProperty scope="context" name="log.totalSizeCap" source="log.total-size-cap" defaultValue="10GB"/>
    <!-- 日志输出级别 -->
    <springProperty scope="context" name="log.root.level" source="log.root.level" defaultValue="info"/>

    <!--控制台日志， 控制台输出 skywalking-->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
            <layout class="org.apache.skywalking.apm.toolkit.log.logback.v1.x.TraceIdPatternLogbackLayout">
                <Pattern>${log.pattern}</Pattern>
            </layout>
        </encoder>
    </appender>

    <!-- 系统日志输出 -->
    <appender name="FILE_INFO" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.path}/sys-info.log</file>
        <!-- 循环政策：基于时间创建日志文件 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件名格式 -->
            <fileNamePattern>${log.path}/sys-info.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>${log.maxHistory}</maxHistory>
            <totalSizeCap>${log.totalSizeCap}</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>${log.pattern}</pattern>
        </encoder>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 过滤的级别 -->
            <level>INFO</level>
            <!-- 匹配时的操作：接收（记录） -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配时的操作：拒绝（不记录） -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="FILE_ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.path}/sys-error.log</file>
        <!-- 循环政策：基于时间创建日志文件 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件名格式 -->
            <fileNamePattern>${log.path}/sys-error.%d{yyyy-MM-dd}.log</fileNamePattern>
            <!--            <maxFileSize>${log.maxFileSize}</maxFileSize>-->
            <maxHistory>${log.maxHistory}</maxHistory>
            <totalSizeCap>${log.totalSizeCap}</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>${log.pattern}</pattern>
        </encoder>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 过滤的级别 -->
            <level>ERROR</level>
            <!-- 匹配时的操作：接收（记录） -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配时的操作：拒绝（不记录） -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!--kafka 心跳 WARN 屏蔽-->
    <logger name="org.apache.kafka.clients.NetworkClient" level="ERROR"/>
    <!--kafka 消费者、生产者配置打印 屏蔽-->
    <logger name="org.apache.kafka.clients.consumer.ConsumerConfig" level="ERROR"/>
    <logger name="org.apache.kafka.clients.producer.ProducerConfig" level="ERROR"/>
    <logger name="org.apache.kafka.clients.admin.AdminClientConfig" level="ERROR"/>

    <!-- 日志输出级别 -->
    <root level="${log.root.level}">
        <appender-ref ref="STDOUT"/>
        <appender-ref ref="FILE_INFO"/>
        <appender-ref ref="FILE_ERROR"/>
    </root>
</configuration>